# Speech Emotion Detection

## Introduction

Speech Emotion Detection is a vital tool that plays a significant role in the realm of Artificial Intelligence. By harnessing these techniques, we can enhance our day-to-day experiences through the implementation of these models. In this notebook, we'll utilize an LSTM (Long Short-Term Memory) Model to predict the emotions conveyed in speech.

## Dataset

For this project, we've employed the Ravdess Emotion Speech Audio Dataset, which comprises 1440 files: 60 trials per actor multiplied by 24 actors, resulting in a total of 1440 recordings. The dataset features 24 professional actors (12 female and 12 male) speaking two lexically-matched statements in a neutral North American accent. The speech emotions encompass expressions of calm, happiness, sadness, anger, fear, surprise, and disgust. Each expression is presented at two levels of emotional intensity (normal and strong), with an additional neutral expression.

You can access the Ravdess Emotion Speech Audio Dataset [here](link_to_the_dataset).
